{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jbred\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jbred\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jbred\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jbred\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jbred\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jbred\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\GMAE\\data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success! DataFrames loaded.\n",
      "------------------------------\n",
      "True Articles: 34975\n",
      "Fake Articles: 43642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Your CWD is D:\\GMAE\\data, so this will now find the files\n",
    "true_file_path = 'DataSet_Misinfo_TRUE.csv'\n",
    "fake_file_path = 'DataSet_Misinfo_FAKE.csv'\n",
    "\n",
    "try:\n",
    "    true_df = pd.read_csv(true_file_path)\n",
    "    fake_df = pd.read_csv(fake_file_path)\n",
    "\n",
    "    print(\"‚úÖ Success! DataFrames loaded.\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"True Articles:\", len(true_df))\n",
    "    print(\"Fake Articles:\", len(fake_df))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Unforeseen Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake DataFrame with target column:\n",
      "   Unnamed: 0                                               text  target\n",
      "0           0  Donald Trump just couldn t wish all Americans ...       0\n",
      "1           1  House Intelligence Committee Chairman Devin Nu...       0\n",
      "2           2  On Friday, it was revealed that former Milwauk...       0\n",
      "3           3  On Christmas day, Donald Trump announced that ...       0\n",
      "4           4  Pope Francis used his annual Christmas Day mes...       0\n",
      "--------------------------------------------------\n",
      "True DataFrame with target column:\n",
      "   Unnamed: 0                                               text  target\n",
      "0           0  The head of a conservative Republican faction ...       1\n",
      "1           1  Transgender people will be allowed for the fir...       1\n",
      "2           2  The special counsel investigation of links bet...       1\n",
      "3           3  Trump campaign adviser George Papadopoulos tol...       1\n",
      "4           4  President Donald Trump called on the U.S. Post...       1\n"
     ]
    }
   ],
   "source": [
    "# Add a 'target' column to label the datasets:\n",
    "# 0 for fake news, 1 for true news (This is a common convention)\n",
    "fake_df['target'] = 0\n",
    "true_df['target'] = 1\n",
    "\n",
    "# Display the first few rows of each new DataFrame to verify the 'target' column\n",
    "print(\"Fake DataFrame with target column:\")\n",
    "print(fake_df.head())\n",
    "print(\"-\" * 50)\n",
    "print(\"True DataFrame with target column:\")\n",
    "print(true_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78617 entries, 0 to 78616\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  78617 non-null  int64 \n",
      " 1   text        78588 non-null  object\n",
      " 2   target      78617 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.8+ MB\n",
      "--------------------------------------------------\n",
      "Combined DataFrame Head (mostly fake news):\n",
      "   Unnamed: 0                                               text  target\n",
      "0           0  Donald Trump just couldn t wish all Americans ...       0\n",
      "1           1  House Intelligence Committee Chairman Devin Nu...       0\n",
      "2           2  On Friday, it was revealed that former Milwauk...       0\n",
      "3           3  On Christmas day, Donald Trump announced that ...       0\n",
      "4           4  Pope Francis used his annual Christmas Day mes...       0\n",
      "--------------------------------------------------\n",
      "Combined DataFrame Tail (mostly true news):\n",
      "       Unnamed: 0                                               text  target\n",
      "78612       34970  Most conservatives who oppose marriage equalit...       1\n",
      "78613       34971  The freshman senator from Georgia quoted scrip...       1\n",
      "78614       34972  The State Department told the Republican Natio...       1\n",
      "78615       34973  ADDIS ABABA, Ethiopia ‚ÄîPresident Obama convene...       1\n",
      "78616       34974  Jeb Bush Is Suddenly Attacking Trump. Here's W...       1\n"
     ]
    }
   ],
   "source": [
    "# Concatenate (stack) the two DataFrames vertically\n",
    "df = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Display the information about the combined DataFrame\n",
    "print(\"Combined DataFrame Information:\")\n",
    "df.info()\n",
    "\n",
    "# Display the first and last few rows to verify the merge\n",
    "print(\"-\" * 50)\n",
    "print(\"Combined DataFrame Head (mostly fake news):\")\n",
    "print(df.head())\n",
    "print(\"-\" * 50)\n",
    "print(\"Combined DataFrame Tail (mostly true news):\")\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value counts per column:\n",
      "Unnamed: 0     0\n",
      "text          29\n",
      "target         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the combined DataFrame\n",
    "print(\"Null value counts per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value counts after cleaning:\n",
      "Unnamed: 0    0\n",
      "text          0\n",
      "target        0\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "New DataFrame size: 78588\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where the 'text' column is null (the 29 missing values)\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "# Re-check for null values to confirm the drop was successful\n",
    "print(\"Null value counts after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Also check the new size of the DataFrame\n",
    "print(\"-\" * 50)\n",
    "print(f\"New DataFrame size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current columns in the DataFrame:\n",
      "['Unnamed: 0', 'text', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Display all current column names in the combined DataFrame\n",
    "print(\"Current columns in the DataFrame:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Final DataFrame Structure:\n",
      "   target                                          full_text\n",
      "0       0  Donald Trump just couldn t wish all Americans ...\n",
      "1       0  House Intelligence Committee Chairman Devin Nu...\n",
      "2       0  On Friday, it was revealed that former Milwauk...\n",
      "3       0  On Christmas day, Donald Trump announced that ...\n",
      "4       0  Pope Francis used his annual Christmas Day mes...\n",
      "--------------------------------------------------\n",
      "Final Columns:\n",
      "Index(['target', 'full_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the 'full_text' feature using only the available 'text' column.\n",
    "# We skip combining with 'title' since that column is missing.\n",
    "df['full_text'] = df['text']\n",
    "\n",
    "# 2. Drop the redundant columns.\n",
    "# We are dropping 'Unnamed: 0' (a leftover index) and the original 'text' column,\n",
    "# now that we have copied its contents into 'full_text'.\n",
    "df.drop(['Unnamed: 0', 'text'], axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows of the final cleaned DataFrame\n",
    "print(\"-\" * 50)\n",
    "print(\"Final DataFrame Structure:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display the final columns to confirm the cleaning is complete\n",
    "print(\"-\" * 50)\n",
    "print(\"Final Columns:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\jbred\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.9.18-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/41.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 41.5/41.5 kB 504.6 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\jbred\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading regex-2025.9.18-cp312-cp312-win_amd64.whl (275 kB)\n",
      "   ---------------------------------------- 0.0/275.5 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 163.8/275.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 275.5/275.5 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.4/308.4 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, joblib, nltk\n",
      "Successfully installed joblib-1.5.2 nltk-3.9.1 regex-2025.9.18 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\jbred\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\jbred\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NLTK stopwords downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jbred\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# This command will open a download window or automatically download the resource\n",
    "nltk.download('stopwords')\n",
    "\n",
    "print(\"‚úÖ NLTK stopwords downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text preprocessing complete.\n",
      "--------------------------------------------------\n",
      "Original Text Example:\n",
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n",
      "--------------------------------------------------\n",
      "Cleaned Text Example:\n",
      "donald trump wish american happi new year leav instead give shout enemi hater dishonest fake news media former realiti show star one job countri rapidli grow stronger smarter want wish friend support enemi hater even dishonest fake news media happi healthi new year presid angri pant tweet great year america countri rapidli grow stronger smarter want wish friend support enemi hater even dishonest fake news media happi healthi new year great year america donald j trump realdonaldtrump decemb trump tweet went welll expect kind presid send new year greet like despic petti infantil gibberish trump lack decenc even allow rise gutter long enough wish american citizen happi new year bishop talbert swan talbertswan decemb one like calvin calvinstowel decemb impeach would make great year america also accept regain control congress miranda yaver mirandayav decemb hear talk includ mani peopl hate wonder hate alan sandov alansandov decemb use word hater new year wish marlen marlen decemb say happi new year koren pollitt korencarpent decemb trump new year eve tweet happi new year includ mani enemi fought lost badli know love donald j trump realdonaldtrump decemb noth new trump year trump direct messag enemi hater new year easter thanksgiv anniversari pic twitter com fpae kypa daniel dale ddale decemb trump holiday tweet clearli presidenti long work hallmark becom presid steven goodin sgoodin decemb alway like differ last year filter break roy schulz thbthttt decemb apart teenag use term hater wendi wendywhistl decemb fuck year old know rainyday decemb peopl vote hole think would chang got power wrong year old men chang year older photo andrew burton getti imag\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Download stopwords if you haven't already (you only need to run this once)\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "all_stopwords = stopwords.words('english')\n",
    "\n",
    "# Function to perform all cleaning and stemming steps\n",
    "def preprocess_text(text):\n",
    "    # 1. Cleaning: Remove non-alphabetic characters and convert to lowercase\n",
    "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    review = review.lower()\n",
    "    \n",
    "    # 2. Tokenization\n",
    "    review = review.split()\n",
    "    \n",
    "    # 3. Stemming and Stopword Removal\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    \n",
    "    # 4. Re-join the words into a single string for Vectorization\n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "# Apply the function to the 'full_text' column\n",
    "df['full_text_cleaned'] = df['full_text'].apply(preprocess_text)\n",
    "\n",
    "print(\"‚úÖ Text preprocessing complete.\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Original Text Example:\")\n",
    "print(df['full_text'].iloc[0])\n",
    "print(\"-\" * 50)\n",
    "print(\"Cleaned Text Example:\")\n",
    "print(df['full_text_cleaned'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\jbred\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.3.3)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.8 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/60.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 60.8/60.8 kB 802.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jbred\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/8.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.0/8.7 MB 12.7 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.6/8.7 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.3/8.7 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.9/8.7 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.2/8.7 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.4/8.7 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.8/8.7 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.0/8.7 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.4/8.7 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.8/8.7 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.2/8.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.4/8.7 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.7/8.7 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 8.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.0/8.7 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.3/8.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.4/8.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.5/8.7 MB 7.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.6/8.7 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.7/8.7 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.9/8.7 MB 6.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.0/8.7 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.1/8.7 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.2/8.7 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.4/8.7 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.5/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.7/8.7 MB 4.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.8/8.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.0/8.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.1/8.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.3/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading scipy-1.16.2-cp312-cp312-win_amd64.whl (38.6 MB)\n",
      "   ---------------------------------------- 0.0/38.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/38.6 MB 5.3 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.3/38.6 MB 3.8 MB/s eta 0:00:11\n",
      "   ---------------------------------------- 0.4/38.6 MB 3.2 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.6/38.6 MB 3.3 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.7/38.6 MB 3.6 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.0/38.6 MB 3.8 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 1.3/38.6 MB 4.3 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 1.6/38.6 MB 4.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.0/38.6 MB 4.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.4/38.6 MB 5.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 2.8/38.6 MB 5.6 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.1/38.6 MB 5.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.5/38.6 MB 5.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 4.1/38.6 MB 6.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 4.4/38.6 MB 6.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 4.9/38.6 MB 6.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.1/38.6 MB 6.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.3/38.6 MB 6.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.4/38.6 MB 6.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.6/38.6 MB 6.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.8/38.6 MB 6.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 5.9/38.6 MB 5.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.0/38.6 MB 5.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.1/38.6 MB 5.5 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.3/38.6 MB 5.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 6.4/38.6 MB 5.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 6.5/38.6 MB 5.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 6.7/38.6 MB 5.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 6.9/38.6 MB 5.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.1/38.6 MB 5.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.4/38.6 MB 5.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 7.6/38.6 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 7.8/38.6 MB 5.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 8.1/38.6 MB 5.1 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.3/38.6 MB 5.1 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 8.7/38.6 MB 5.2 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 8.9/38.6 MB 5.2 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 9.3/38.6 MB 5.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 9.8/38.6 MB 5.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 10.1/38.6 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 10.3/38.6 MB 5.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 10.6/38.6 MB 5.5 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 10.9/38.6 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 11.3/38.6 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 11.7/38.6 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 11.9/38.6 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.2/38.6 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.4/38.6 MB 5.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.6/38.6 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 12.8/38.6 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.1/38.6 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.2/38.6 MB 5.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 13.4/38.6 MB 5.4 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 13.6/38.6 MB 5.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 13.8/38.6 MB 5.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 13.9/38.6 MB 5.1 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.0/38.6 MB 5.0 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.1/38.6 MB 4.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 14.2/38.6 MB 4.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 14.3/38.6 MB 4.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 14.5/38.6 MB 4.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 14.7/38.6 MB 4.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 15.0/38.6 MB 4.6 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 15.2/38.6 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 15.4/38.6 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 15.7/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 16.0/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 16.3/38.6 MB 4.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.5/38.6 MB 4.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.8/38.6 MB 5.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.1/38.6 MB 5.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 17.4/38.6 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 17.6/38.6 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 17.8/38.6 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 17.9/38.6 MB 5.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.1/38.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.3/38.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.4/38.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.4/38.6 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 18.4/38.6 MB 4.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 18.6/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 18.8/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 19.0/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 19.3/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.6/38.6 MB 4.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.9/38.6 MB 4.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 20.0/38.6 MB 4.5 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 20.4/38.6 MB 4.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 20.8/38.6 MB 4.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.3/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.7/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.8/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 22.1/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 22.4/38.6 MB 4.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 22.5/38.6 MB 4.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 22.8/38.6 MB 4.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 23.0/38.6 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.2/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.5/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.7/38.6 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.9/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 24.0/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.2/38.6 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.3/38.6 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.4/38.6 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.6/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.8/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 25.0/38.6 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.3/38.6 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.6/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.0/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.3/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.6/38.6 MB 5.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.8/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.1/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.3/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.7/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.9/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.1/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.3/38.6 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.4/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.5/38.6 MB 4.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.7/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 28.9/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.1/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.4/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.5/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 29.9/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.3/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.1/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.3/38.6 MB 5.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.6/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 31.9/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.1/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.3/38.6 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.3/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.5/38.6 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.6/38.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 32.8/38.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.0/38.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.1/38.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.2/38.6 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.3/38.6 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.5/38.6 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 33.8/38.6 MB 4.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 34.0/38.6 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.4/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.5/38.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 34.9/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.0/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.2/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.3/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.6/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.9/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.4/38.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.6/38.6 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.9/38.6 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.3/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.7/38.6 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.4/38.6 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.6/38.6 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.7.2 scipy-1.16.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text Vectorization complete.\n",
      "--------------------------------------------------\n",
      "Original number of documents (rows): 78588\n",
      "Vectorized Feature Matrix Shape (rows, features): (78588, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df['full_text_cleaned']\n",
    "y = df['target']\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the cleaned text data\n",
    "X_vectorized = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "print(\"‚úÖ Text Vectorization complete.\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Original number of documents (rows): {len(X)}\")\n",
    "print(f\"Vectorized Feature Matrix Shape (rows, features): {X_vectorized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data split complete.\n",
      "Training Features (X_train) shape: (62870, 5000)\n",
      "Testing Features (X_test) shape: (15718, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_vectorized is the feature matrix, y is the target array\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"‚úÖ Data split complete.\")\n",
    "print(f\"Training Features (X_train) shape: {X_train.shape}\")\n",
    "print(f\"Testing Features (X_test) shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting model training...\n",
      "‚úÖ Model training complete.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model using the training data\n",
    "print(\"üöÄ Starting model training...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"‚úÖ Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation ---\n",
      "Accuracy: 0.9312\n",
      "Precision: 0.9310\n",
      "Recall: 0.9127\n",
      "F1-Score: 0.9218\n",
      "--------------------\n",
      "Confusion Matrix:\n",
      "[[8269  472]\n",
      " [ 609 6368]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model and Vectorizer successfully saved to the './model_assets/' folder!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Assuming 'model' (LogisticRegression) and 'vectorizer' (TfidfVectorizer) \n",
    "# are available from your previous cells.\n",
    "\n",
    "# Define the folder where you want to save the assets\n",
    "save_dir = './model_assets/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save the Trained Model\n",
    "with open(os.path.join(save_dir, 'model.pkl'), 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "    \n",
    "# 2. Save the Vectorizer\n",
    "with open(os.path.join(save_dir, 'vectorizer.pkl'), 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "print(f\"‚úÖ Model and Vectorizer successfully saved to the '{save_dir}' folder!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
